# ü§ñ Claso - AI Code Comment & Commit Message Generator

A production-quality machine learning web application that generates intelligent code comments and commit messages using custom-trained transformer models. Features both lightweight and enhanced models with real ML (no API wrappers) - built for hackathons and production use.

## üöÄ Features

- **Real ML Models**: Custom transformer architecture with multiple model sizes (4.8M to 80M parameters)
- **Dual Generation**: Professional code comments and context-aware commit messages
- **Multi-Language Support**: Python and JavaScript with language-specific comment styles
- **Full-Stack**: React frontend with glassmorphism UI + FastAPI backend
- **Production Ready**: Advanced training pipeline with monitoring and optimization
- **Apple Silicon Optimized**: Native MPS support for M-series chips
- **Hackathon Winner**: Impressive demos with professional-grade output
- **Interactive Web Interface**: Modern React frontend with Monaco Editor and real-time generation

## üèóÔ∏è Architecture Overview

### Frontend (React + TypeScript)
- Modern glassmorphism UI with Tailwind CSS
- Monaco Editor for code input with syntax highlighting
- Floating navbar and responsive design
- Real-time generation with multiple model options

### Backend (Python + FastAPI)
- Custom transformer models (4.8M to 80M parameters)
- Real-time inference API with caching
- Advanced model serving and optimization
- Comprehensive training and monitoring pipeline

### ML Pipeline
- Advanced GitHub data collection (5,000+ samples)
- Enhanced tokenization and preprocessing
- Multi-scale transformer training
- Production-quality model optimization

üìã **For detailed architecture diagrams and technical documentation, see [ARCHITECTURE.md](ARCHITECTURE.md)**

> üí° **Visual learner?** Check out the architecture diagrams below to understand the system at a glance!

### üìä System Architecture Diagrams

![System Overview](diagrams/chart2.png)
*Complete system architecture showing frontend, backend, ML models, and data pipeline*

![Model Architecture](diagrams/model-architecture.png)
*FastEnhancedTransformer architecture with attention mechanisms and layer details*

![API Flow](diagrams/chart3.png)
*REST API request/response flow and endpoint structure*

![Training Pipeline](diagrams/chart4.png)
*ML training process from data collection to model deployment*

![Data Pipeline](diagrams/chart5.png)
*Data collection and processing pipeline from GitHub to training datasets*

![Frontend Architecture](diagrams/chart6.png)
*React frontend component structure and user interaction flow*

![Application Demo](diagrams/chat1.png)
*Claso application interface showing code comment generation in action*



## üß† Model Architecture & Mathematics

### Model Variants

#### 1. Lightweight Models (Legacy)
**Comment Model:**
- Parameters: ~4.8M
- Architecture: d_model=128, layers=2+2, heads=4
- Context: 512 tokens
- Training time: ~30 minutes
- Use case: Quick demos, resource-constrained environments

**Commit Model:**
- Parameters: ~11.7M  
- Architecture: d_model=256, layers=4+4, heads=8
- Context: 1024 tokens
- Training time: ~45 minutes
- Use case: Basic commit message generation

#### 2. Fast Enhanced Models (Recommended)
**Fast Comment Model:**
- Parameters: ~15M
- Architecture: d_model=256, layers=4+4, heads=8
- Context: 512 tokens
- Training time: ~45 minutes
- Use case: Optimal balance of speed and quality

**Fast Commit Model:**
- Parameters: ~25M
- Architecture: d_model=384, layers=5+5, heads=12
- Context: 512 tokens
- Training time: ~60 minutes
- Use case: Production-ready commit messages

#### 3. Full Enhanced Models (Maximum Quality)
**Enhanced Comment Model:**
- Parameters: ~50M
- Architecture: d_model=512, layers=8+8, heads=16
- Context: 2048 tokens
- Training time: ~90 minutes
- Use case: Professional docstring generation

**Enhanced Commit Model:**
- Parameters: ~80M
- Architecture: d_model=768, layers=10+10, heads=16  
- Context: 2048 tokens
- Training time: ~120 minutes
- Use case: Context-aware commit messages

### Mathematical Foundation

#### Transformer Architecture
```
MultiHeadAttention(Q,K,V) = Concat(head‚ÇÅ,...,head‚Çï)W^O
where head·µ¢ = Attention(QW·µ¢^Q, KW·µ¢^K, VW·µ¢^V)

Attention(Q,K,V) = softmax(QK^T/‚àöd‚Çñ)V

FeedForward(x) = GELU(xW‚ÇÅ + b‚ÇÅ)W‚ÇÇ + b‚ÇÇ
```

#### Parameter Calculations
```
Enhanced Comment Model (~50M params):
- Embeddings: vocab_size √ó d_model = 10K √ó 512 = 5.1M
- Encoder: 8 √ó (4 √ó d_model¬≤ + 4 √ó d_model √ó d_ff) ‚âà 25M  
- Decoder: 8 √ó (6 √ó d_model¬≤ + 4 √ó d_model √ó d_ff) ‚âà 20M
- Total: ~50M parameters
```

#### Training Optimization
- **Mixed Precision**: FP16 training for 2x speedup (CUDA only)
- **Gradient Checkpointing**: Trade compute for memory
- **Learning Rate Schedule**: Warmup + cosine decay
- **Label Smoothing**: Œµ = 0.1 for better generalization

## üìã Prerequisites

- Python 3.8+
- Node.js 16+
- Git
- 8GB+ RAM (16GB+ recommended for enhanced models)
- Optional: GPU with 8GB+ VRAM for faster training

## üöÄ Quick Start

### 1. Clone Repository
```bash
git clone https://github.com/Akash8585/claso.git
cd claso
```

### 2. Backend Setup
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Environment Configuration
```bash
cp .env.example .env
# Add your GitHub token for data collection
```

### 4. Choose Your Training Path

#### Option A: Fast Enhanced Training (Recommended - 1-1.5 hours)
```bash
# Optimal balance of quality and speed
python fast_enhanced_train.py
```

#### Option B: Full Enhanced Training (2-3 hours)
```bash
# Maximum quality models
python setup_enhanced_models.py
python train_enhanced.py
```

#### Option C: Smart Adaptive Training
```bash
# Automatically adapts to your data size
python smart_enhanced_train.py --no-wait
```

### 5. Start Backend
```bash
python main.py
```

### 6. Test Enhanced Models
```bash
# Verify models are working correctly
python test_enhanced_api.py
```

### 7. Frontend Setup
```bash
cd ../frontend
npm install
npm run dev
```

### 8. Access Application
- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Model Info**: http://localhost:8000/model-info

## üîß Configuration

### Environment Variables

#### Backend (.env)
```env
# GitHub token for data collection
GITHUB_TOKEN=your_github_personal_access_token

# Model paths
MODEL_PATH=models/best_model.pth
TOKENIZER_PATH=models/tokenizer.pkl

# CORS settings
ALLOWED_ORIGINS=http://localhost:5173,https://yourdomain.com
```

#### Frontend (.env)
```env
# Backend API URL
VITE_API_URL=http://localhost:8000
```

#### How to get GitHub Token:
1. Go to GitHub Settings ‚Üí Developer settings ‚Üí Personal access tokens
2. Generate new token with `repo` scope for public repositories
3. [GitHub Token Guide](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token)

### Training Configuration
```python
# Enhanced model config
TrainingConfig(
    model_type='comment',           # 'comment' or 'commit'
    batch_size=6,                   # Adjust for your GPU memory
    learning_rate=5e-5,             # Learning rate
    num_epochs=25,                  # Training epochs
    warmup_steps=4000,              # Warmup steps
    use_mixed_precision=True,       # FP16 training (CUDA only)
    gradient_checkpointing=True,    # Memory optimization
    accumulation_steps=4,           # Gradient accumulation
)
```

## üìä Training Pipeline

### Data Collection
```bash
# Basic collection (500+ samples)
python tools/data_collector.py

# Advanced collection (5,000+ samples)
python tools/advanced_data_collector.py

# Commit message data
python tools/commit_data_collector.py
```

### Model Training Options

#### Quick Training (Lightweight)
```bash
python quick_train.py          # Fast training
python train.py               # Standard training
python continue_training.py   # Resume training
```

#### Enhanced Training (Production)
```bash
python train_enhanced.py      # Full enhanced pipeline
python train_now.py          # Immediate training
python smart_enhanced_train.py # Adaptive training
```

### Training Monitoring
```bash
# Live training monitor
python monitor_training.py

# Check logs
tail -f logs/enhanced_*_training.log

# View training plots
ls plots/
```

## üéì Model Performance Comparison

### Quality Metrics

| Model Type | Parameters | BLEU-4 | ROUGE-L | Inference Speed | Memory |
|------------|------------|--------|---------|-----------------|--------|
| Lightweight Comment | 4.8M | 0.35 | 0.32 | ~20ms | ~50MB |
| **Fast Comment** | **15M** | **0.48** | **0.45** | **~40ms** | **~100MB** |
| Enhanced Comment | 50M | 0.58 | 0.55 | ~80ms | ~200MB |
| Lightweight Commit | 11.7M | 0.28 | 0.31 | ~30ms | ~80MB |
| **Fast Commit** | **25M** | **0.42** | **0.38** | **~60ms** | **~150MB** |
| Enhanced Commit | 80M | 0.52 | 0.49 | ~120ms | ~300MB |

### Output Quality Examples

#### Lightweight Model Output:
```python
def calculate_sum(numbers):
    """Calculate sum of numbers."""
    return sum(numbers)
```

#### Enhanced Model Output:
```python
def calculate_sum(numbers):
    """
    Calculate the sum of all numbers in the provided list.
    
    This function iterates through the input list and returns
    the cumulative sum of all numeric values.
    
    Args:
        numbers (list): List of numbers to sum
        
    Returns:
        int/float: Total sum of all numbers in the input list
        
    Example:
        >>> calculate_sum([1, 2, 3, 4, 5])
        15
    """
    return sum(numbers)
```

## üñ•Ô∏è Hardware Requirements & Performance

### Minimum Requirements
- **CPU**: 4+ cores
- **RAM**: 8GB
- **Storage**: 5GB
- **Training Time**: 2-4 hours (CPU)

### Recommended (Apple Silicon)
- **CPU**: M1/M2/M3/M4 Mac
- **RAM**: 16GB+
- **Storage**: 10GB
- **Training Time**: 1-2 hours (MPS)

### Optimal (NVIDIA GPU)
- **GPU**: RTX 3060+ (8GB VRAM)
- **RAM**: 16GB+
- **Storage**: 10GB
- **Training Time**: 30-60 minutes

## üåê API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/generate-comments` | Generate code comments |
| `POST` | `/generate-diff` | Generate diff from uploaded files |
| `POST` | `/generate-commit-msg` | Generate commit message from diff |
| `GET` | `/health` | Health check |
| `GET` | `/model-info` | Model information and stats |

### Example API Usage

```bash
# Generate comments
curl -X POST "http://localhost:8000/generate-comments" \
  -H "Content-Type: application/json" \
  -d '{
    "code": "def fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)",
    "language": "python",
    "style": "docstring"
  }'

# Health check
curl http://localhost:8000/health
```

## ÔøΩÔ∏è eDevelopment

### Project Structure
```
claso/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # FastAPI server
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ production_transformer.py # Model architectures
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py      # Enhanced data processing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ *.json                 # Training datasets
‚îÇ   ‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ advanced_data_collector.py # GitHub data collection
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ commit_data_collector.py   # Commit message data
‚îÇ   ‚îú‚îÄ‚îÄ logs/                      # Training logs
‚îÇ   ‚îú‚îÄ‚îÄ models/                    # Saved models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fast_comment/          # Fast comment models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fast_commit/           # Fast commit models
‚îÇ   ‚îî‚îÄ‚îÄ plots/                     # Training visualizations
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Navbar.tsx         # Floating glassmorphism navbar
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Assistant.tsx      # Main application page
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ public/
‚îú‚îÄ‚îÄ diagrams/                      # Architecture diagrams
‚îÇ   ‚îú‚îÄ‚îÄ chart2.png                 # System overview architecture
‚îÇ   ‚îú‚îÄ‚îÄ chart3.png                 # API flow and endpoints
‚îÇ   ‚îú‚îÄ‚îÄ chart4.png                 # Training pipeline process
‚îÇ   ‚îú‚îÄ‚îÄ chart5.png                 # Data collection pipeline
‚îÇ   ‚îú‚îÄ‚îÄ chart6.png                 # Frontend architecture
‚îÇ   ‚îú‚îÄ‚îÄ chat1.png                  # Application demo interface
‚îÇ   ‚îî‚îÄ‚îÄ model-architecture.png     # ML model structure
‚îú‚îÄ‚îÄ ARCHITECTURE.md                # Detailed technical documentation
‚îî‚îÄ‚îÄ README.md
```

## üìà Monitoring & Logging

### Training Monitoring
```bash
# Live monitor with progress bars
python monitor_training.py

# Check specific model logs
tail -f logs/fast_comment_training.log
tail -f logs/fast_commit_training.log

# View training plots
open plots/fast_comment_training_history.png
```

### Model Testing & Validation
```bash
# Test enhanced API endpoints
python test_enhanced_api.py

# Check model information
curl http://localhost:8000/model-info

# Validate model loading
python -c "
import torch
from model.production_transformer import FastEnhancedTransformer
model = torch.load('models/fast_comment/comment_best.pth')
print('Fast Enhanced Model loaded successfully')
"
```

### Performance Monitoring
```bash
# Check model sizes
ls -lh models/fast_*/

# Monitor API health
curl http://localhost:8000/health

# View API documentation
open http://localhost:8000/docs
```

## üö® Troubleshooting

### Apple Silicon Issues
```bash
# Check MPS availability
python -c "import torch; print(torch.backends.mps.is_available())"

# Disable mixed precision for MPS
export USE_MIXED_PRECISION=false
```

### Memory Issues
```bash
# Reduce batch size
export BATCH_SIZE=4

# Enable gradient checkpointing
export GRADIENT_CHECKPOINTING=true

# Use CPU if needed
export FORCE_CPU=true
```

### Training Issues
```bash
# Check data availability
ls data/*.json

# Verify model architecture
python -c "from model.production_transformer import EnhancedProductionTransformer; print('OK')"

# Monitor training
python monitor_training.py
```

### Common Issues

**1. CUDA/GPU Issues**
```bash
# Check GPU availability
python -c "import torch; print(torch.cuda.is_available())"

# Use CPU training if needed
export CUDA_VISIBLE_DEVICES=""
```

**2. Data Collection Issues**
```bash
# Set GitHub token
export GITHUB_TOKEN=your_token_here

# Check rate limits
python -c "import requests; print(requests.get('https://api.github.com/rate_limit').json())"
```

## ü§ù Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- Transformer architecture based on "Attention Is All You Need" (Vaswani et al.)
- Advanced training techniques from modern NLP research
- GitHub API for high-quality data collection
- Apple Silicon MPS optimization
- Monaco Editor for VS Code-like editing experience
- Open source community for tools and libraries

## üìû Support

For questions and support:
- Create an issue on GitHub
- Check the troubleshooting section
- Review the comprehensive documentation
- Monitor training logs for debugging

---

**Built for hackathons, optimized for production, ready to win!** üöÄüèÜ 